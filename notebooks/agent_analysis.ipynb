{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72b8436",
   "metadata": {},
   "source": [
    "# Agent Performance Analysis and Comparison\n",
    "\n",
    "First run `python -m src.rl.evaluate` to generate the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e8c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from src import plotting_utils\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(context='paper', style='ticks', font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972b8c9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Update these paths to match your setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c863de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = \"10x10\"  # Set the correct grid size\n",
    "results_path = f\"../outputs/results/{grid_size}/testing\"\n",
    "figures_path = f\"../figures/analysis/{grid_size}\"\n",
    "\n",
    "# Create figures directory if it doesn't exist\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# set figure parameters\n",
    "width_pt = 469"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521972ee",
   "metadata": {},
   "source": [
    "Load all available evaluation results from the testing directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f36c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 JSON files in ../outputs/results/10x10/testing\n",
      "Loaded comprehensive results from: all_agents_evaluation_20250814_231830.json\n",
      "\n",
      "Loaded results for 9 agents: ['DQN', 'Random', 'Gen Greedy (r=1)', 'Gen Greedy (r=2)', 'Gen Greedy (r=3)', 'Gen Greedy (r=4)', 'Gen Greedy (r=5)', 'Gen Greedy (r=6)', 'Gen Greedy (r=7)']\n"
     ]
    }
   ],
   "source": [
    "def load_evaluation_results(results_path):\n",
    "\n",
    "    all_results = {}\n",
    "    \n",
    "    # Look for all JSON files in the results directory\n",
    "    json_files = glob(os.path.join(results_path, \"*.json\"))\n",
    "    \n",
    "    print(f\"Found {len(json_files)} JSON files in {results_path}\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Check if this is a comprehensive evaluation file (multiple agents)\n",
    "            if isinstance(data, dict) and 'DQN' in data and 'Random' in data:\n",
    "                # This is a comprehensive evaluation file\n",
    "                for agent_name, agent_results in data.items():\n",
    "                    all_results[agent_name] = agent_results\n",
    "                print(f\"Loaded comprehensive results from: {os.path.basename(json_file)}\")\n",
    "            \n",
    "            # Check if this is a single agent evaluation file\n",
    "            elif isinstance(data, dict) and 'agent_type' in data:\n",
    "                agent_type = data['agent_type']\n",
    "                all_results[agent_type.upper()] = data\n",
    "                print(f\"Loaded {agent_type} results from: {os.path.basename(json_file)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nLoaded results for {len(all_results)} agents: {list(all_results.keys())}\")\n",
    "    return all_results\n",
    "\n",
    "all_results = load_evaluation_results(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369db07",
   "metadata": {},
   "source": [
    "Create a bar plot comparing all agents on the percentage of cells saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d344342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.latexify()\n",
    "\n",
    "fig_width, fig_height = plotting_utils.get_fig_dim(width_pt, fraction=0.8)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "plot_data = []\n",
    "for name, results in all_results.items():\n",
    "    for instance_result in results['instance_results']:\n",
    "        plot_data.append({\n",
    "            'Agent': name, \n",
    "            'Cells Saved (%)': instance_result['cells_saved_pct']\n",
    "        })\n",
    "plot_data = pd.DataFrame(plot_data)\n",
    "\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(plot_data['Agent'].unique()))\n",
    "sns.barplot(data=plot_data, x='Agent', y='Cells Saved (%)', hue='Agent', errorbar='ci', ax=ax, palette=palette)\n",
    "sns.despine(ax=ax)\n",
    "# show a grid in the background every 10 on the y axis\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "ax.grid(True)\n",
    "\n",
    "ax.set_xlabel('Agent')\n",
    "ax.set_ylabel(r'Cells Saved (\\%)')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "fig.tight_layout()\n",
    "comparison_plot_path = f\"{figures_path}/agent_comparison_{timestamp}.png\"\n",
    "fig.savefig(comparison_plot_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6145aa",
   "metadata": {},
   "source": [
    "Analyze agent performance across different difficulty levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710cb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.latexify()\n",
    "\n",
    "fig_width, fig_height = plotting_utils.get_fig_dim(width_pt, fraction=1.0)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "difficulty_order = ['very_easy', 'easy', 'medium', 'hard', 'very_hard']\n",
    "\n",
    "difficulty_data = []\n",
    "for agent_name, results in all_results.items():\n",
    "    for instance_result in results['instance_results']:\n",
    "        difficulty = instance_result.get('difficulty', 'unknown')\n",
    "        if difficulty in difficulty_order:\n",
    "            difficulty_data.append({\n",
    "                'Agent': agent_name,\n",
    "                'Difficulty': difficulty,\n",
    "                'Cells Saved (%)': instance_result['cells_saved_pct']\n",
    "            })\n",
    "\n",
    "difficulty_df = pd.DataFrame(difficulty_data)\n",
    "\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(difficulty_df['Agent'].unique()))\n",
    "sns.barplot(data=difficulty_df, x='Difficulty', y='Cells Saved (%)', \n",
    "            hue='Agent', order=difficulty_order, errorbar='ci', ax=ax, palette=palette)\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "ax.set_xlabel('Difficulty Level')\n",
    "ax.set_ylabel(r'Cells Saved (\\%)')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "difficulty_plot_path = f\"{figures_path}/difficulty_comparison_{timestamp}.png\"\n",
    "fig.savefig(difficulty_plot_path, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a17ed0",
   "metadata": {},
   "source": [
    "Plot how the DQN agent's test set performance evolved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8842c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DQN test scores from: dqn_test_scores_20250814_184057.json\n",
      "Found 30 evaluation points\n",
      "Episode range: 5000 to 150000\n",
      "Score range: 34.9% to 55.5%\n"
     ]
    }
   ],
   "source": [
    "# Look for DQN test scores file\n",
    "logs_path = f\"../outputs/logs/{grid_size}/dqn\"\n",
    "score_files = glob(os.path.join(logs_path, \"dqn_test_scores_*.json\"))\n",
    "\n",
    "# Use the most recent file\n",
    "score_files.sort(key=os.path.getmtime, reverse=True)\n",
    "score_file = score_files[0]\n",
    "\n",
    "print(f\"Loading DQN test scores from: {os.path.basename(score_file)}\")\n",
    "\n",
    "# Load the data\n",
    "with open(score_file, 'r') as f:\n",
    "    score_data = json.load(f)\n",
    "\n",
    "# Extract episodes and scores\n",
    "episodes = [entry['episode'] for entry in score_data]\n",
    "test_scores = [entry['dqn_test_score'] for entry in score_data]\n",
    "\n",
    "print(f\"Found {len(episodes)} evaluation points\")\n",
    "print(f\"Episode range: {episodes[0]} to {episodes[-1]}\")\n",
    "print(f\"Score range: {min(test_scores):.1f}% to {max(test_scores):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81757a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.latexify()\n",
    "\n",
    "fig_width, fig_height = plotting_utils.get_fig_dim(width_pt, fraction=0.8)\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create DataFrame for seaborn plotting\n",
    "training_df = pd.DataFrame({\n",
    "    'Episode': episodes,\n",
    "    'Score': test_scores\n",
    "})\n",
    "\n",
    "sns.lineplot(data=training_df, x='Episode', y='Score', ax=ax)\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "ax.set_xlabel('Training Episodes')\n",
    "ax.set_ylabel(r'Test Set Score (\\% Tiles Saved)')\n",
    "\n",
    "fig.tight_layout()\n",
    "training_plot_path = f\"{figures_path}/dqn_training_progress_{timestamp}.png\"\n",
    "fig.savefig(training_plot_path, dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
